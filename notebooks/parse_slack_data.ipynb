{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud # error module not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud #error fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path to import modules from src\n",
    "rpath = os.path.abspath('..')\n",
    "if rpath not in sys.path:\n",
    "    sys.path.insert(0, rpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loader import SlackDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns we can get from a slack message<br>\n",
    "\n",
    "message_type, message_content, sender_id, time_sent, message_distribution, time_thread_start, reply_count, reply_user_count, time_thread_end, reply_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a single slack message, we can get <br>\n",
    "\n",
    "1. The message<br>\n",
    "2. Type (message, file, link, etc)<br>\n",
    "3. The sender_id (assigned by slack)<br>\n",
    "4. The time the message was sent<br>\n",
    "5. The team (i don't know what that is now)<br>\n",
    "6. The type of the message (broadcast message, inhouse, just messgae)<br>\n",
    "7. The thread the message generated (from here we can go):<br>\n",
    "    7.1 Text/content of the message<br>\n",
    "    7.2 The thread time of the message<br>\n",
    "    7.3 The thread count (reply count)<br>\n",
    "    7.4 The number of user that reply the message (count of users that participated in the thread)<br>\n",
    "    7.5 The time the last thread message was sent <br>\n",
    "    7.6 The users that participated in the thread (their ids are stored as well)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slack_parser(path_channel):\n",
    "    \"\"\"Parse Slack data to extract useful information from the JSON files.\n",
    "\n",
    "    Args:\n",
    "        path_channel (str): Path to the directory containing the JSON files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Extracted information combined into a DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a list to store the combined data from JSON files\n",
    "    combined_data = []\n",
    "\n",
    "    # Read all JSON files from the provided path\n",
    "    json_files = glob.glob(f\"{path_channel}/*.json\")\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file, 'r', encoding=\"utf8\") as slack_data:\n",
    "                data = json.load(slack_data)\n",
    "                combined_data.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading JSON file '{json_file}': {str(e)}\")\n",
    "\n",
    "    # Define lists to store the extracted information\n",
    "    msg_type, msg_content, sender_id, time_msg, msg_dist, time_thread_st = [], [], [], [], [], []\n",
    "    reply_count, reply_users_count, reply_users, tm_thread_end = [], [], [], []\n",
    "\n",
    "    # Loop through the combined data and extract the required information\n",
    "    for row in combined_data:\n",
    "        if 'bot_id' in row.keys():\n",
    "            continue\n",
    "        else:\n",
    "            msg_type.append(row.get('type'))\n",
    "            msg_content.append(row.get('text'))\n",
    "            sender = row.get('user_profile')\n",
    "            if sender:\n",
    "                sender_id.append(sender.get('real_name'))\n",
    "            else:\n",
    "                sender_id.append('Not provided')\n",
    "            time_msg.append(row.get('ts'))\n",
    "            blocks = row.get('blocks')\n",
    "            if blocks and len(blocks[0]['elements'][0]['elements']) > 0:\n",
    "                msg_dist.append(blocks[0]['elements'][0]['elements'][0]['type'])\n",
    "            else:\n",
    "                msg_dist.append('reshared')\n",
    "            thread_ts = row.get('thread_ts')\n",
    "            if thread_ts:\n",
    "                time_thread_st.append(thread_ts)\n",
    "            else:\n",
    "                time_thread_st.append(0)\n",
    "            reply_users.append(\",\".join(row.get('reply_users', [])))\n",
    "            reply_count.append(row.get('reply_count', 0))\n",
    "            reply_users_count.append(row.get('reply_users_count', 0))\n",
    "            tm_thread_end.append(row.get('latest_reply', 0))\n",
    "\n",
    "    # Create a DataFrame from the extracted information\n",
    "    data = zip(msg_type, msg_content, sender_id, time_msg, msg_dist, time_thread_st,\n",
    "               reply_count, reply_users_count, reply_users, tm_thread_end)\n",
    "    columns = ['msg_type', 'msg_content', 'sender_name', 'msg_sent_time', 'msg_dist_type',\n",
    "               'time_thread_start', 'reply_count', 'reply_users_count', 'reply_users', 'tm_thread_end']\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "    # Filter out rows where sender_name is 'Not provided'\n",
    "    df = df[df['sender_name'] != 'Not provided']\n",
    "\n",
    "    # Add a 'channel' column to the DataFrame indicating the channel name\n",
    "    channel_name = path_channel.split('/')[-1].split('.')[0]\n",
    "    df['channel'] = channel_name\n",
    "\n",
    "    # Reset the index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path ='../data/anonymized/all-community-building/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_slack = slack_parser(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      \n",
       "1      \n",
       "2      \n",
       "3      \n",
       "4      \n",
       "     ..\n",
       "95     \n",
       "96     \n",
       "97     \n",
       "98     \n",
       "99     \n",
       "Name: channel, Length: 100, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_slack['channel'].head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_slack_reaction(path, channel):\n",
    "    \"\"\"get reactions\"\"\"\n",
    "    dfall_reaction = pd.DataFrame()\n",
    "    combined = []\n",
    "    for json_file in glob.glob(f\"{path}*.json\"):\n",
    "        with open(json_file, 'r') as slack_data:\n",
    "            combined.append(slack_data)\n",
    "\n",
    "    reaction_name, reaction_count, reaction_users, msg, user_id = [], [], [], [], []\n",
    "\n",
    "    for k in combined:\n",
    "        slack_data = json.load(open(k.name, 'r', encoding=\"utf-8\"))\n",
    "        \n",
    "        for i_count, i in enumerate(slack_data):\n",
    "            if 'reactions' in i.keys():\n",
    "                for j in range(len(i['reactions'])):\n",
    "                    msg.append(i['text'])\n",
    "                    user_id.append(i['user'])\n",
    "                    reaction_name.append(i['reactions'][j]['name'])\n",
    "                    reaction_count.append(i['reactions'][j]['count'])\n",
    "                    reaction_users.append(\",\".join(i['reactions'][j]['users']))\n",
    "                \n",
    "    data_reaction = zip(reaction_name, reaction_count, reaction_users, msg, user_id)\n",
    "    columns_reaction = ['reaction_name', 'reaction_count', 'reaction_users_count', 'message', 'user_id']\n",
    "    df_reaction = pd.DataFrame(data=data_reaction, columns=columns_reaction)\n",
    "    df_reaction['channel'] = channel\n",
    "    return df_reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_reaction = parse_slack_reaction(file_path, 'channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3191 entries, 0 to 3190\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   reaction_name         3191 non-null   object\n",
      " 1   reaction_count        3191 non-null   int64 \n",
      " 2   reaction_users_count  3191 non-null   object\n",
      " 3   message               3191 non-null   object\n",
      " 4   user_id               3191 non-null   object\n",
      " 5   channel               3191 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 149.7+ KB\n"
     ]
    }
   ],
   "source": [
    "parsed_reaction.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction_name</th>\n",
       "      <th>reaction_count</th>\n",
       "      <th>reaction_users_count</th>\n",
       "      <th>message</th>\n",
       "      <th>user_id</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+1</td>\n",
       "      <td>12</td>\n",
       "      <td>U03UFV7TUTV,U03U1HAG9TR,U03UFV7HFNF,U03U9EJR36...</td>\n",
       "      <td>hi all, looking forward to starting together, ...</td>\n",
       "      <td>U03U93GNNVB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muscle</td>\n",
       "      <td>2</td>\n",
       "      <td>U03UG0YHAUT,U03UUR571A5</td>\n",
       "      <td>hi all, looking forward to starting together, ...</td>\n",
       "      <td>U03U93GNNVB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heart</td>\n",
       "      <td>2</td>\n",
       "      <td>U03UUMM7Y8H,U03UD68RQH3</td>\n",
       "      <td>hi all, looking forward to starting together, ...</td>\n",
       "      <td>U03U93GNNVB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+1</td>\n",
       "      <td>8</td>\n",
       "      <td>U03UFV7HFNF,U03UG4Q7V42,U03U9EJR362,U03U1J51VF...</td>\n",
       "      <td>hello everyone. it's my hope that you are doin...</td>\n",
       "      <td>U03V1AM5TFA</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clap</td>\n",
       "      <td>2</td>\n",
       "      <td>U03U1HAG9TR,U03UG0YHAUT</td>\n",
       "      <td>hello everyone. it's my hope that you are doin...</td>\n",
       "      <td>U03V1AM5TFA</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>+1</td>\n",
       "      <td>5</td>\n",
       "      <td>U03UG4Q7V42,U03U9EJR362,U03UFV7TUTV,U03UG0YHAU...</td>\n",
       "      <td>*community building session reminder!*:timer_c...</td>\n",
       "      <td>U03V1AM5TFA</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>+1</td>\n",
       "      <td>8</td>\n",
       "      <td>U03UUMM7Y8H,U03UHB8CXDY,U03UFV7HFNF,U03UG0YHAU...</td>\n",
       "      <td>hello people, congratulations for making it to...</td>\n",
       "      <td>U03V1AM5TFA</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>grinning</td>\n",
       "      <td>1</td>\n",
       "      <td>U03V1AM5TFA</td>\n",
       "      <td>why did my mind go blank at first:joy:</td>\n",
       "      <td>U03U1HAG9TR</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grinning</td>\n",
       "      <td>1</td>\n",
       "      <td>U03U1HAG9TR</td>\n",
       "      <td>mirrors - justin timberlake:hugging_face:</td>\n",
       "      <td>U03U1FNPEUX</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>U03U1FNPEUX</td>\n",
       "      <td>sia :rolling_on_the_floor_laughing:- unstoppable</td>\n",
       "      <td>U03U9EJR362</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reaction_name  reaction_count  \\\n",
       "0            +1              12   \n",
       "1        muscle               2   \n",
       "2         heart               2   \n",
       "3            +1               8   \n",
       "4          clap               2   \n",
       "5            +1               5   \n",
       "6            +1               8   \n",
       "7      grinning               1   \n",
       "8      grinning               1   \n",
       "9           100               1   \n",
       "\n",
       "                                reaction_users_count  \\\n",
       "0  U03UFV7TUTV,U03U1HAG9TR,U03UFV7HFNF,U03U9EJR36...   \n",
       "1                            U03UG0YHAUT,U03UUR571A5   \n",
       "2                            U03UUMM7Y8H,U03UD68RQH3   \n",
       "3  U03UFV7HFNF,U03UG4Q7V42,U03U9EJR362,U03U1J51VF...   \n",
       "4                            U03U1HAG9TR,U03UG0YHAUT   \n",
       "5  U03UG4Q7V42,U03U9EJR362,U03UFV7TUTV,U03UG0YHAU...   \n",
       "6  U03UUMM7Y8H,U03UHB8CXDY,U03UFV7HFNF,U03UG0YHAU...   \n",
       "7                                        U03V1AM5TFA   \n",
       "8                                        U03U1HAG9TR   \n",
       "9                                        U03U1FNPEUX   \n",
       "\n",
       "                                             message      user_id  channel  \n",
       "0  hi all, looking forward to starting together, ...  U03U93GNNVB  channel  \n",
       "1  hi all, looking forward to starting together, ...  U03U93GNNVB  channel  \n",
       "2  hi all, looking forward to starting together, ...  U03U93GNNVB  channel  \n",
       "3  hello everyone. it's my hope that you are doin...  U03V1AM5TFA  channel  \n",
       "4  hello everyone. it's my hope that you are doin...  U03V1AM5TFA  channel  \n",
       "5  *community building session reminder!*:timer_c...  U03V1AM5TFA  channel  \n",
       "6  hello people, congratulations for making it to...  U03V1AM5TFA  channel  \n",
       "7             why did my mind go blank at first:joy:  U03U1HAG9TR  channel  \n",
       "8          mirrors - justin timberlake:hugging_face:  U03U1FNPEUX  channel  \n",
       "9   sia :rolling_on_the_floor_laughing:- unstoppable  U03U9EJR362  channel  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_reaction.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_community_participation(path):\n",
    "    \"\"\" specify path to get json files\"\"\"\n",
    "    combined = []\n",
    "    comm_dict = {}\n",
    "    for json_file in glob.glob(f\"{path}*.json\"):\n",
    "        with open(json_file, 'r') as slack_data:\n",
    "            combined.append(slack_data)\n",
    "    print(f\"Total json files is {len(combined)}\")\n",
    "    for i in combined:\n",
    "        a = json.load(open(i.name, 'r', encoding='utf-8'))\n",
    "\n",
    "        for msg in a:\n",
    "            if 'replies' in msg.keys():\n",
    "                for i in msg['replies']:\n",
    "                    comm_dict[i['user']] = comm_dict.get(i['user'], 0)+1\n",
    "    return comm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total json files is 79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "get_community =get_community_participation(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'U03UG0YHAUT': 112,\n",
       " 'U03V1AM5TFA': 515,\n",
       " 'U03V785NLSU': 118,\n",
       " 'U03UUS0MZCZ': 106,\n",
       " 'U03UG32J3PC': 358,\n",
       " 'U03U1HAG9TR': 135,\n",
       " 'U03UG1RTXAP': 14,\n",
       " 'U03UUMM7Y8H': 26,\n",
       " 'U03UD68RQH3': 224,\n",
       " 'U03UJGFG2HJ': 7,\n",
       " 'U03U1FNPEUX': 145,\n",
       " 'U03UG4Q7V42': 199,\n",
       " 'U03UFV7HFNF': 53,\n",
       " 'U03UD5B7C3X': 66,\n",
       " 'U03UFV7TUTV': 39,\n",
       " 'U03UHB8CXDY': 77,\n",
       " 'U03UKGSDGSG': 6,\n",
       " 'U03UUR571A5': 266,\n",
       " 'U03UD4FEDHB': 24,\n",
       " 'U03UP7V9Q57': 2,\n",
       " 'U03UJN29Y4C': 55,\n",
       " 'U03UVHCV6KB': 284,\n",
       " 'U03UJKJGRAQ': 132,\n",
       " 'U03U1FQKEMV': 3,\n",
       " 'U03U9FWPNCE': 32,\n",
       " 'U03TT5KEYCF': 13,\n",
       " 'U03TEPYRM2P': 14,\n",
       " 'U03UCCRJME2': 1,\n",
       " 'U03U93GNNVB': 46,\n",
       " 'U03U9EJR362': 39,\n",
       " 'U03T89ACUUW': 39,\n",
       " 'U03UJGP0C68': 168,\n",
       " 'U03UJH1EQQL': 24,\n",
       " 'U03UJGRN5E0': 28,\n",
       " 'U03V5Q9N516': 44,\n",
       " 'U03V6HMRPGQ': 164,\n",
       " 'U03U1J51VFZ': 19,\n",
       " 'U03UAKATQ22': 34,\n",
       " 'U03UG0SFHGT': 42,\n",
       " 'U03UH397319': 99,\n",
       " 'U03UG5VFN03': 13,\n",
       " 'U03UUMR26Q1': 15,\n",
       " 'U03U4GULU3Y': 2,\n",
       " 'U03UG1Z21JP': 80,\n",
       " 'U03U1GHT39V': 6,\n",
       " 'U03UGB3T3MY': 1,\n",
       " 'U03UUP56MDF': 1,\n",
       " 'U03V61VGQG0': 4}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_2_timestamp(column, data):\n",
    "    \"\"\"convert from unix time to readable timestamp\n",
    "        args: column: columns that needs to be converted to timestamp\n",
    "                data: data that has the specified column\n",
    "    \"\"\"\n",
    "    if column in data.columns.values:\n",
    "        timestamp_ = []\n",
    "        for time_unix in data[column]:\n",
    "            if time_unix == 0:\n",
    "                timestamp_.append(0)\n",
    "            else:\n",
    "                a = datetime.datetime.fromtimestamp(float(time_unix))\n",
    "                timestamp_.append(a.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        return timestamp_\n",
    "    else: \n",
    "        print(f\"{column} not in data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tagged_users(df):\n",
    "    \"\"\"get all @ in the messages\"\"\"\n",
    "\n",
    "    return df['msg_content'].map(lambda x: re.findall(r'@U\\w+', x))\n",
    "\n",
    "\n",
    "    \n",
    "def map_userid_2_realname(user_profile: dict, comm_dict: dict, plot=False):\n",
    "    \"\"\"\n",
    "    map slack_id to realnames\n",
    "    user_profile: a dictionary that contains users info such as real_names\n",
    "    comm_dict: a dictionary that contains slack_id and total_message sent by that slack_id\n",
    "    \"\"\"\n",
    "    user_dict = {} # to store the id\n",
    "    real_name = [] # to store the real name\n",
    "    ac_comm_dict = {} # to store the mapping\n",
    "    count = 0\n",
    "    # collect all the real names\n",
    "    for i in range(len(user_profile['profile'])):\n",
    "        real_name.append(dict(user_profile['profile'])[i]['real_name'])\n",
    "\n",
    "    # loop the slack ids\n",
    "    for i in user_profile['id']:\n",
    "        user_dict[i] = real_name[count]\n",
    "        count += 1\n",
    "\n",
    "    # to store mapping\n",
    "    for i in comm_dict:\n",
    "        if i in user_dict:\n",
    "            ac_comm_dict[user_dict[i]] = comm_dict[i]\n",
    "\n",
    "    ac_comm_dict = pd.DataFrame(data= zip(ac_comm_dict.keys(), ac_comm_dict.values()),\n",
    "    columns=['LearnerName', '# of Msg sent in Threads']).sort_values(by='# of Msg sent in Threads', ascending=False)\n",
    "    \n",
    "    if plot:\n",
    "        ac_comm_dict.plot.bar(figsize=(15, 7.5), x='LearnerName', y='# of Msg sent in Threads')\n",
    "        plt.title('Student based on Message sent in thread', size=20)\n",
    "        \n",
    "    return ac_comm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_20_user(data, channel='Random'):\n",
    "    \"\"\"get user with the highest number of message sent to any channel\"\"\"\n",
    "\n",
    "    data['sender_name'].value_counts()[:20].plot.bar(figsize=(15, 7.5))\n",
    "    plt.title(f'Top 20 Message Senders in #{channel} channels', size=15, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=14);\n",
    "    plt.xticks(size=12); plt.yticks(size=12);\n",
    "    plt.show()\n",
    "\n",
    "    data['sender_name'].value_counts()[-10:].plot.bar(figsize=(15, 7.5))\n",
    "    plt.title(f'Bottom 10 Message Senders in #{channel} channels', size=15, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=14);\n",
    "    plt.xticks(size=12); plt.yticks(size=12);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_avg_reply_count(data, channel='Random'):\n",
    "    \"\"\"who commands many reply?\"\"\"\n",
    "\n",
    "    data.groupby('sender_name')['reply_count'].mean().sort_values(ascending=False)[:20]\\\n",
    "        .plot(kind='bar', figsize=(15,7.5));\n",
    "    plt.title(f'Average Number of reply count per Sender in #{channel}', size=20, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=18);\n",
    "    plt.xticks(size=14); plt.yticks(size=14);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_avg_reply_users_count(data, channel='Random'):\n",
    "    \"\"\"who commands many user reply?\"\"\"\n",
    "\n",
    "    data.groupby('sender_name')['reply_users_count'].mean().sort_values(ascending=False)[:20].plot(kind='bar',\n",
    "     figsize=(15,7.5));\n",
    "    plt.title(f'Average Number of reply user count per Sender in #{channel}', size=20, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=18);\n",
    "    plt.xticks(size=14); plt.yticks(size=14);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_wordcloud(msg_content, week):    \n",
    "    # word cloud visualization\n",
    "    allWords = ' '.join([twts for twts in msg_content])\n",
    "    wordCloud = WordCloud(background_color='#975429', width=500, height=300, random_state=21, max_words=500, mode='RGBA',\n",
    "                            max_font_size=140, stopwords=stopwords.words('english')).generate(allWords)\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    plt.imshow(wordCloud, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.title(f'WordCloud for {week}', size=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_user_reaction(data, channel='General'):\n",
    "    data.groupby('sender_name')[['reply_count', 'reply_users_count']].sum()\\\n",
    "        .sort_values(by='reply_count',ascending=False)[:10].plot(kind='bar', figsize=(15, 7.5))\n",
    "    plt.title(f'User with the most reaction in #{channel}', size=25);\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=18);\n",
    "    plt.xticks(size=14); plt.yticks(size=14);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insight Extraction\n",
    "\n",
    "Below are some useful questions to answer. Feel free to explore to answer other interesting questions that may be of help to get insight about student's behaviour, need, and future performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which user has the highest number of reply counts?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reply counts per user per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the time range of the day that most messages are sent?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what kind of messages are replied faster than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between # of messages and # of reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify messages into different categories such as questions, answers, comments, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which users got the most reactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model topics mentioned in the channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the topics that got the most reactions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harder questions to look into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on messages, reactions, references shared, and other relevant data such as classification of questions into techical question, comment, answer, aorder stu the python, statistics, and sql skill level of a user?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
